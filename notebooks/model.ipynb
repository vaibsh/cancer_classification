{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60ea9a52-0e85-4d7f-9a5c-aa7f2a8b02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset as HFDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfa3eade-014b-4604-bce5-5ef3365ab555",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31055803</td>\n",
       "      <td>Analysis of age-specific cytogenetic changes a...</td>\n",
       "      <td>OBJECTIVE: To characterize cytogenetic changes...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31164412</td>\n",
       "      <td>T-Cell Deletion of MyD88 Connects IL17 and Ika...</td>\n",
       "      <td>Cancer development requires a favorable tissue...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31094905</td>\n",
       "      <td>MYCN Amplified Relapse Following Resolution of...</td>\n",
       "      <td>Congenital neuroblastoma with placental involv...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31498304</td>\n",
       "      <td>In Vivo Inhibition of MicroRNA to Decrease Tum...</td>\n",
       "      <td>MicroRNAs (miRNAs) are important regulators of...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30897768</td>\n",
       "      <td>Breast Cancer and miR-SNPs: The Importance of ...</td>\n",
       "      <td>Recent studies in cancer diagnostics have iden...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>26095439</td>\n",
       "      <td>Urinary 11beta-PGF2alpha and N-methyl histamin...</td>\n",
       "      <td>BACKGROUND: The utility of measuring histamine...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24850616</td>\n",
       "      <td>A limited form of proteus syndrome with bilate...</td>\n",
       "      <td>IMPORTANCE: Proteus syndrome is an extremely r...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>24402730</td>\n",
       "      <td>Benign mast cell hyperplasia and atypical mast...</td>\n",
       "      <td>Introduction. Lichen planus (LP) is a chronic ...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>26513044</td>\n",
       "      <td>Nevus anemicus associated with neurofibromatos...</td>\n",
       "      <td>Neurofibromatosis type 1 (NF1) is a multisyste...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>24688314</td>\n",
       "      <td>Comparison of methods for the extraction of DN...</td>\n",
       "      <td>AIM: Discussing a protocol involving xylene-et...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              Title  \\\n",
       "0    31055803  Analysis of age-specific cytogenetic changes a...   \n",
       "1    31164412  T-Cell Deletion of MyD88 Connects IL17 and Ika...   \n",
       "2    31094905  MYCN Amplified Relapse Following Resolution of...   \n",
       "3    31498304  In Vivo Inhibition of MicroRNA to Decrease Tum...   \n",
       "4    30897768  Breast Cancer and miR-SNPs: The Importance of ...   \n",
       "..        ...                                                ...   \n",
       "995  26095439  Urinary 11beta-PGF2alpha and N-methyl histamin...   \n",
       "996  24850616  A limited form of proteus syndrome with bilate...   \n",
       "997  24402730  Benign mast cell hyperplasia and atypical mast...   \n",
       "998  26513044  Nevus anemicus associated with neurofibromatos...   \n",
       "999  24688314  Comparison of methods for the extraction of DN...   \n",
       "\n",
       "                                              Abstract    Category  \n",
       "0    OBJECTIVE: To characterize cytogenetic changes...      Cancer  \n",
       "1    Cancer development requires a favorable tissue...      Cancer  \n",
       "2    Congenital neuroblastoma with placental involv...      Cancer  \n",
       "3    MicroRNAs (miRNAs) are important regulators of...      Cancer  \n",
       "4    Recent studies in cancer diagnostics have iden...      Cancer  \n",
       "..                                                 ...         ...  \n",
       "995  BACKGROUND: The utility of measuring histamine...  Non-Cancer  \n",
       "996  IMPORTANCE: Proteus syndrome is an extremely r...  Non-Cancer  \n",
       "997  Introduction. Lichen planus (LP) is a chronic ...  Non-Cancer  \n",
       "998  Neurofibromatosis type 1 (NF1) is a multisyste...  Non-Cancer  \n",
       "999  AIM: Discussing a protocol involving xylene-et...  Non-Cancer  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to read text files and extract required data\n",
    "def parse_text_files(base_path):\n",
    "    data = []\n",
    "    \n",
    "    for category in ['Cancer', 'Non-Cancer']:\n",
    "        folder_path = os.path.join(base_path, category)\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Ensure we only process text files\n",
    "            if not filename.endswith(\".txt\"):\n",
    "                continue\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                lines = file.readlines()\n",
    "                \n",
    "                # Extracting ID, Title, and Abstract\n",
    "                id_ = filename.replace('.txt', '')  # File name = ID\n",
    "                title = ''\n",
    "                abstract = ''\n",
    "                if len(lines) > 1:\n",
    "                    title = lines[1].strip().replace('Title: ', '')  # Second line = title\n",
    "                    title = re.sub(r'^\\W+|\\W+$', '', title)\n",
    "                if len(lines) > 2:\n",
    "                    abstract = ' '.join(line.strip() for line in lines[2:])  # Rest is Abstract\n",
    "                    abstract = abstract.replace('Abstract: ', '')\n",
    "                    abstract = re.sub(r'^\\W+|\\W+$', '', abstract)\n",
    "                data.append([id_, title, abstract, category])\n",
    "\n",
    "    # Creating DataFrame\n",
    "    df = pd.DataFrame(data, columns=[\"ID\", \"Title\", \"Abstract\", \"Category\"])\n",
    "    return df\n",
    "\n",
    "# Parse dataset and create DataFrame\n",
    "df = parse_text_files('Dataset')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57729b93-b12a-475e-88a3-cb898ad8e27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31055803</td>\n",
       "      <td>Analysis of age-specific cytogenetic changes a...</td>\n",
       "      <td>OBJECTIVE: To characterize cytogenetic changes...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31164412</td>\n",
       "      <td>T-Cell Deletion of MyD88 Connects IL17 and Ika...</td>\n",
       "      <td>Cancer development requires a favorable tissue...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31094905</td>\n",
       "      <td>MYCN Amplified Relapse Following Resolution of...</td>\n",
       "      <td>Congenital neuroblastoma with placental involv...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31498304</td>\n",
       "      <td>In Vivo Inhibition of MicroRNA to Decrease Tum...</td>\n",
       "      <td>MicroRNAs (miRNAs) are important regulators of...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30897768</td>\n",
       "      <td>Breast Cancer and miR-SNPs: The Importance of ...</td>\n",
       "      <td>Recent studies in cancer diagnostics have iden...</td>\n",
       "      <td>Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>26095439</td>\n",
       "      <td>Urinary 11beta-PGF2alpha and N-methyl histamin...</td>\n",
       "      <td>BACKGROUND: The utility of measuring histamine...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24850616</td>\n",
       "      <td>A limited form of proteus syndrome with bilate...</td>\n",
       "      <td>IMPORTANCE: Proteus syndrome is an extremely r...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>24402730</td>\n",
       "      <td>Benign mast cell hyperplasia and atypical mast...</td>\n",
       "      <td>Introduction. Lichen planus (LP) is a chronic ...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>26513044</td>\n",
       "      <td>Nevus anemicus associated with neurofibromatos...</td>\n",
       "      <td>Neurofibromatosis type 1 (NF1) is a multisyste...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>24688314</td>\n",
       "      <td>Comparison of methods for the extraction of DN...</td>\n",
       "      <td>AIM: Discussing a protocol involving xylene-et...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              Title  \\\n",
       "0    31055803  Analysis of age-specific cytogenetic changes a...   \n",
       "1    31164412  T-Cell Deletion of MyD88 Connects IL17 and Ika...   \n",
       "2    31094905  MYCN Amplified Relapse Following Resolution of...   \n",
       "3    31498304  In Vivo Inhibition of MicroRNA to Decrease Tum...   \n",
       "4    30897768  Breast Cancer and miR-SNPs: The Importance of ...   \n",
       "..        ...                                                ...   \n",
       "995  26095439  Urinary 11beta-PGF2alpha and N-methyl histamin...   \n",
       "996  24850616  A limited form of proteus syndrome with bilate...   \n",
       "997  24402730  Benign mast cell hyperplasia and atypical mast...   \n",
       "998  26513044  Nevus anemicus associated with neurofibromatos...   \n",
       "999  24688314  Comparison of methods for the extraction of DN...   \n",
       "\n",
       "                                              Abstract    Category  \n",
       "0    OBJECTIVE: To characterize cytogenetic changes...      Cancer  \n",
       "1    Cancer development requires a favorable tissue...      Cancer  \n",
       "2    Congenital neuroblastoma with placental involv...      Cancer  \n",
       "3    MicroRNAs (miRNAs) are important regulators of...      Cancer  \n",
       "4    Recent studies in cancer diagnostics have iden...      Cancer  \n",
       "..                                                 ...         ...  \n",
       "995  BACKGROUND: The utility of measuring histamine...  Non-Cancer  \n",
       "996  IMPORTANCE: Proteus syndrome is an extremely r...  Non-Cancer  \n",
       "997  Introduction. Lichen planus (LP) is a chronic ...  Non-Cancer  \n",
       "998  Neurofibromatosis type 1 (NF1) is a multisyste...  Non-Cancer  \n",
       "999  AIM: Discussing a protocol involving xylene-et...  Non-Cancer  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    df = df.dropna(subset=['Title', 'Abstract', 'Category'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f406b096-1334-4a2b-bdcc-f54cc7ff532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"<token>\")\n",
    "# Load BioMiniBERT tokenizer and model\n",
    "MODEL_NAME = \"nlpie/tiny-biobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e358b030-d2f4-4fc4-9a02-30eef504aaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31055803</td>\n",
       "      <td>Analysis of age-specific cytogenetic changes a...</td>\n",
       "      <td>OBJECTIVE: To characterize cytogenetic changes...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31164412</td>\n",
       "      <td>T-Cell Deletion of MyD88 Connects IL17 and Ika...</td>\n",
       "      <td>Cancer development requires a favorable tissue...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31094905</td>\n",
       "      <td>MYCN Amplified Relapse Following Resolution of...</td>\n",
       "      <td>Congenital neuroblastoma with placental involv...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31498304</td>\n",
       "      <td>In Vivo Inhibition of MicroRNA to Decrease Tum...</td>\n",
       "      <td>MicroRNAs (miRNAs) are important regulators of...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30897768</td>\n",
       "      <td>Breast Cancer and miR-SNPs: The Importance of ...</td>\n",
       "      <td>Recent studies in cancer diagnostics have iden...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>26095439</td>\n",
       "      <td>Urinary 11beta-PGF2alpha and N-methyl histamin...</td>\n",
       "      <td>BACKGROUND: The utility of measuring histamine...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24850616</td>\n",
       "      <td>A limited form of proteus syndrome with bilate...</td>\n",
       "      <td>IMPORTANCE: Proteus syndrome is an extremely r...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>24402730</td>\n",
       "      <td>Benign mast cell hyperplasia and atypical mast...</td>\n",
       "      <td>Introduction. Lichen planus (LP) is a chronic ...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>26513044</td>\n",
       "      <td>Nevus anemicus associated with neurofibromatos...</td>\n",
       "      <td>Neurofibromatosis type 1 (NF1) is a multisyste...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>24688314</td>\n",
       "      <td>Comparison of methods for the extraction of DN...</td>\n",
       "      <td>AIM: Discussing a protocol involving xylene-et...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              Title  \\\n",
       "0    31055803  Analysis of age-specific cytogenetic changes a...   \n",
       "1    31164412  T-Cell Deletion of MyD88 Connects IL17 and Ika...   \n",
       "2    31094905  MYCN Amplified Relapse Following Resolution of...   \n",
       "3    31498304  In Vivo Inhibition of MicroRNA to Decrease Tum...   \n",
       "4    30897768  Breast Cancer and miR-SNPs: The Importance of ...   \n",
       "..        ...                                                ...   \n",
       "995  26095439  Urinary 11beta-PGF2alpha and N-methyl histamin...   \n",
       "996  24850616  A limited form of proteus syndrome with bilate...   \n",
       "997  24402730  Benign mast cell hyperplasia and atypical mast...   \n",
       "998  26513044  Nevus anemicus associated with neurofibromatos...   \n",
       "999  24688314  Comparison of methods for the extraction of DN...   \n",
       "\n",
       "                                              Abstract    Category  Label  \n",
       "0    OBJECTIVE: To characterize cytogenetic changes...      Cancer      1  \n",
       "1    Cancer development requires a favorable tissue...      Cancer      1  \n",
       "2    Congenital neuroblastoma with placental involv...      Cancer      1  \n",
       "3    MicroRNAs (miRNAs) are important regulators of...      Cancer      1  \n",
       "4    Recent studies in cancer diagnostics have iden...      Cancer      1  \n",
       "..                                                 ...         ...    ...  \n",
       "995  BACKGROUND: The utility of measuring histamine...  Non-Cancer      0  \n",
       "996  IMPORTANCE: Proteus syndrome is an extremely r...  Non-Cancer      0  \n",
       "997  Introduction. Lichen planus (LP) is a chronic ...  Non-Cancer      0  \n",
       "998  Neurofibromatosis type 1 (NF1) is a multisyste...  Non-Cancer      0  \n",
       "999  AIM: Discussing a protocol involving xylene-et...  Non-Cancer      0  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Label column Cancer = 1 and Non-Cancer = 0\n",
    "label_mapping = {'Non-Cancer': 0, 'Cancer': 1}\n",
    "df['Label'] = df['Category'].map(label_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf5c436-2df8-412a-9b85-a363f66eaf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into Train (70%), Validation (10%) & Test (20%)\n",
    "train_texts, tmp_texts, train_labels, tmp_labels = train_test_split(df['Abstract'], df['Label'], test_size=0.3, random_state=42)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(df['Abstract'], df['Label'], test_size=2/3, random_state=42)\n",
    "\n",
    "# Tokenize text\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert to HuggingFace Dataset\n",
    "train_dataset = HFDataset.from_dict({\"input_ids\": train_encodings[\"input_ids\"], \"attention_mask\": train_encodings[\"attention_mask\"], \"labels\": list(train_labels)})\n",
    "val_dataset = HFDataset.from_dict({\"input_ids\": val_encodings[\"input_ids\"], \"attention_mask\": val_encodings[\"attention_mask\"], \"labels\": list(val_labels)})\n",
    "test_dataset = HFDataset.from_dict({\"input_ids\": test_encodings[\"input_ids\"], \"attention_mask\": test_encodings[\"attention_mask\"], \"labels\": list(test_labels)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae51d398-8def-4780-89c0-51adf4ff0b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nlpie/tiny-biobert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 312, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 312)\n",
       "      (token_type_embeddings): Embedding(2, 312)\n",
       "      (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-3): 4 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (key): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (value): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "              (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=312, out_features=1200, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1200, out_features=312, bias=True)\n",
       "            (LayerNorm): LayerNorm((312,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=312, out_features=312, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=312, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BioMiniBERT model for binary classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n",
    "device = 'cpu'\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b587a5a5-ffde-4828-9373-84af553a6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46\n",
      "F1 Score: 0.07\n",
      "Confusion Matrix:\n",
      " [[ 20 480]\n",
      " [ 57 443]]\n"
     ]
    }
   ],
   "source": [
    "# Performance on base model\n",
    "import torch.nn.functional as F\n",
    "def predict(text):\n",
    "    # Tokenize the input and move to device\n",
    "    inputs = tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Get model predictions without computing gradients\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = F.softmax(logits, dim=1).squeeze().cpu().numpy()  # Convert to NumPy\n",
    "        predicted_label = \"Cancer\" if torch.argmax(logits, dim=1).item() == 1 else \"Non-Cancer\"\n",
    "\n",
    "    return pd.Series([predicted_label, float(probs[0]), float(probs[1])])\n",
    "\n",
    "# Apply predictions to the dataset\n",
    "df[[\"Predicted_Category\", \"Non-Cancer Score\", \"Cancer Score\"]] = df[\"Abstract\"].apply(predict)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(df[\"Category\"], df[\"Predicted_Category\"])\n",
    "f1 = f1_score(df[\"Category\"], df[\"Predicted_Category\"], pos_label=\"Cancer\")\n",
    "conf_matrix = confusion_matrix(df[\"Category\"], df[\"Predicted_Category\"])\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0a4b52-ee8b-49e1-af68-d7d059479e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Category</th>\n",
       "      <th>Label</th>\n",
       "      <th>Predicted_Category</th>\n",
       "      <th>Non-Cancer Score</th>\n",
       "      <th>Cancer Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31055803</td>\n",
       "      <td>Analysis of age-specific cytogenetic changes a...</td>\n",
       "      <td>OBJECTIVE: To characterize cytogenetic changes...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.509001</td>\n",
       "      <td>0.490999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31164412</td>\n",
       "      <td>T-Cell Deletion of MyD88 Connects IL17 and Ika...</td>\n",
       "      <td>Cancer development requires a favorable tissue...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.501005</td>\n",
       "      <td>0.498995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31094905</td>\n",
       "      <td>MYCN Amplified Relapse Following Resolution of...</td>\n",
       "      <td>Congenital neuroblastoma with placental involv...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.501208</td>\n",
       "      <td>0.498792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31498304</td>\n",
       "      <td>In Vivo Inhibition of MicroRNA to Decrease Tum...</td>\n",
       "      <td>MicroRNAs (miRNAs) are important regulators of...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.501152</td>\n",
       "      <td>0.498848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30897768</td>\n",
       "      <td>Breast Cancer and miR-SNPs: The Importance of ...</td>\n",
       "      <td>Recent studies in cancer diagnostics have iden...</td>\n",
       "      <td>Cancer</td>\n",
       "      <td>1</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.506756</td>\n",
       "      <td>0.493244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>26095439</td>\n",
       "      <td>Urinary 11beta-PGF2alpha and N-methyl histamin...</td>\n",
       "      <td>BACKGROUND: The utility of measuring histamine...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.510474</td>\n",
       "      <td>0.489526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>24850616</td>\n",
       "      <td>A limited form of proteus syndrome with bilate...</td>\n",
       "      <td>IMPORTANCE: Proteus syndrome is an extremely r...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.504556</td>\n",
       "      <td>0.495444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>24402730</td>\n",
       "      <td>Benign mast cell hyperplasia and atypical mast...</td>\n",
       "      <td>Introduction. Lichen planus (LP) is a chronic ...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.506013</td>\n",
       "      <td>0.493987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>26513044</td>\n",
       "      <td>Nevus anemicus associated with neurofibromatos...</td>\n",
       "      <td>Neurofibromatosis type 1 (NF1) is a multisyste...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.502532</td>\n",
       "      <td>0.497468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>24688314</td>\n",
       "      <td>Comparison of methods for the extraction of DN...</td>\n",
       "      <td>AIM: Discussing a protocol involving xylene-et...</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-Cancer</td>\n",
       "      <td>0.500882</td>\n",
       "      <td>0.499118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                              Title  \\\n",
       "0    31055803  Analysis of age-specific cytogenetic changes a...   \n",
       "1    31164412  T-Cell Deletion of MyD88 Connects IL17 and Ika...   \n",
       "2    31094905  MYCN Amplified Relapse Following Resolution of...   \n",
       "3    31498304  In Vivo Inhibition of MicroRNA to Decrease Tum...   \n",
       "4    30897768  Breast Cancer and miR-SNPs: The Importance of ...   \n",
       "..        ...                                                ...   \n",
       "995  26095439  Urinary 11beta-PGF2alpha and N-methyl histamin...   \n",
       "996  24850616  A limited form of proteus syndrome with bilate...   \n",
       "997  24402730  Benign mast cell hyperplasia and atypical mast...   \n",
       "998  26513044  Nevus anemicus associated with neurofibromatos...   \n",
       "999  24688314  Comparison of methods for the extraction of DN...   \n",
       "\n",
       "                                              Abstract    Category  Label  \\\n",
       "0    OBJECTIVE: To characterize cytogenetic changes...      Cancer      1   \n",
       "1    Cancer development requires a favorable tissue...      Cancer      1   \n",
       "2    Congenital neuroblastoma with placental involv...      Cancer      1   \n",
       "3    MicroRNAs (miRNAs) are important regulators of...      Cancer      1   \n",
       "4    Recent studies in cancer diagnostics have iden...      Cancer      1   \n",
       "..                                                 ...         ...    ...   \n",
       "995  BACKGROUND: The utility of measuring histamine...  Non-Cancer      0   \n",
       "996  IMPORTANCE: Proteus syndrome is an extremely r...  Non-Cancer      0   \n",
       "997  Introduction. Lichen planus (LP) is a chronic ...  Non-Cancer      0   \n",
       "998  Neurofibromatosis type 1 (NF1) is a multisyste...  Non-Cancer      0   \n",
       "999  AIM: Discussing a protocol involving xylene-et...  Non-Cancer      0   \n",
       "\n",
       "    Predicted_Category  Non-Cancer Score  Cancer Score  \n",
       "0           Non-Cancer          0.509001      0.490999  \n",
       "1           Non-Cancer          0.501005      0.498995  \n",
       "2           Non-Cancer          0.501208      0.498792  \n",
       "3           Non-Cancer          0.501152      0.498848  \n",
       "4           Non-Cancer          0.506756      0.493244  \n",
       "..                 ...               ...           ...  \n",
       "995         Non-Cancer          0.510474      0.489526  \n",
       "996         Non-Cancer          0.504556      0.495444  \n",
       "997         Non-Cancer          0.506013      0.493987  \n",
       "998         Non-Cancer          0.502532      0.497468  \n",
       "999         Non-Cancer          0.500882      0.499118  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d48adf-79e5-4968-a666-345a96bd718e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 0, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.179123</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>0.961783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.135400</td>\n",
       "      <td>0.107324</td>\n",
       "      <td>0.969970</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9705882352941176\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 0, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.151200</td>\n",
       "      <td>0.076300</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>0.981013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.065049</td>\n",
       "      <td>0.987988</td>\n",
       "      <td>0.987261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9824046920821115\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 0, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.984985</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.073800</td>\n",
       "      <td>0.067349</td>\n",
       "      <td>0.984985</td>\n",
       "      <td>0.984127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9882697947214076\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 100, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.143900</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.993631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.016819</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.996825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9897810218978103\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 100, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:54, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.072211</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.032230</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9855072463768116\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 100, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 02:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.996825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050299</td>\n",
       "      <td>0.993994</td>\n",
       "      <td>0.993711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9883381924198251\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 500, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112858</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9898107714701602\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 500, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123439</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9912536443148688\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 2, 'warmup_steps': 500, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='176' max='176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [176/176 00:55, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137138</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9912536443148688\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 3, 'warmup_steps': 0, 'weight_decay': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 01:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045686</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.996825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9898403483309144\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 3, 'warmup_steps': 0, 'weight_decay': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [264/264 01:23, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012154</td>\n",
       "      <td>0.996997</td>\n",
       "      <td>0.996845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [84/84 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9898403483309144\n",
      "Testing params: {'batch_size': 8, 'learning_rate': 5e-05, 'num_epochs': 3, 'warmup_steps': 0, 'weight_decay': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/qj/ypc_ffp5563c8z81157j9f480000gn/T/ipykernel_38510/588070563.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='137' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [137/264 00:41 < 00:38, 3.28 it/s, Epoch 1.55/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m ParameterGrid(param_grid):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 80\u001b[0m     trainer, metrics \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./biobert_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     f1 \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1)\n",
      "Cell \u001b[0;32mIn[10], line 57\u001b[0m, in \u001b[0;36mfine_tune\u001b[0;34m(model, tokenizer, train_dataset, val_dataset, output_dir, batch_size, num_epochs, weight_decay, learning_rate, use_cuda)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m: acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m: f1}\n\u001b[1;32m     48\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     49\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     50\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 57\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Save model and tokenizer\u001b[39;00m\n\u001b[1;32m     60\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/trainer.py:2553\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m   2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs, num_items_in_batch)\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "def fine_tune(model, tokenizer, train_dataset, val_dataset, output_dir, batch_size=8, \n",
    "              num_epochs=3, weight_decay=0.01, learning_rate=5e-05, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Fine-tune model with custom hyperparameters.\n",
    "\n",
    "    Parameters:\n",
    "    - model: HuggingFace model\n",
    "    - tokenizer: HuggingFace tokenizer\n",
    "    - train_dataset: Dataset for training\n",
    "    - val_dataset: Dataset for evaluation\n",
    "    - output_dir: Directory to save fine-tuned model\n",
    "    - batch_size: Training and eval batch size\n",
    "    - num_epochs: Number of training epochs\n",
    "    - weight_decay: Weight decay (L2 regularization)\n",
    "    - learning_rate: Learning Rate\n",
    "    - use_cuda: Use GPU if True\n",
    "\n",
    "    Returns:\n",
    "    - trainer: Trained HuggingFace Trainer object\n",
    "    - metrics: Final evaluation metrics\n",
    "    \"\"\"\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=num_epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        learning_rate=learning_rate,\n",
    "        logging_steps=10,\n",
    "        save_steps=500,\n",
    "        save_total_limit=2,\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=not use_cuda\n",
    "    )\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        acc = accuracy_score(labels, preds)\n",
    "        f1 = f1_score(labels, preds)\n",
    "        return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Save model and tokenizer\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "    metrics = trainer.evaluate(test_dataset)\n",
    "    return trainer, metrics\n",
    "\n",
    "param_grid = {\n",
    "    \"batch_size\": [8, 16],\n",
    "    \"num_epochs\": [2, 3, 5],\n",
    "    \"weight_decay\": [0.0, 0.01, 0.1],\n",
    "    \"learning_rate\": [5e-5, 3e-5, 2e-5],\n",
    "    \"warmup_steps\": [0, 100, 500]\n",
    "}\n",
    "\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "best_trainer = None\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing params: {params}\")\n",
    "    trainer, metrics = fine_tune(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        val_dataset=val_dataset,\n",
    "        output_dir=f\"./biobert_{params['batch_size']}_{params['num_epochs']}_{params['weight_decay']}\",\n",
    "        batch_size=params['batch_size'],\n",
    "        num_epochs=params['num_epochs'],\n",
    "        weight_decay=params['weight_decay'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        use_cuda=True\n",
    "    )\n",
    "\n",
    "    f1 = metrics[\"eval_f1\"]\n",
    "    print(\"F1 Score:\", f1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_params = params\n",
    "        best_trainer = trainer\n",
    "\n",
    "print(f\"\\nBest F1: {best_f1:.4f} with params: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f2acaf-77af-4ae6-95d4-bc98390599d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance on fine-tuned model\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "print(f\"Test Accuracy: {test_results['eval_accuracy']:.4f}\")\n",
    "print(f\"Test F1 Score: {test_results['eval_f1']:.4f}\")\n",
    "\n",
    "# Get Predictions on CPU\n",
    "predictions = trainer.predict(test_dataset).predictions\n",
    "pred_labels = torch.tensor(predictions).argmax(dim=-1).cpu().numpy()\n",
    "true_labels = torch.tensor(np.array(test_labels)).cpu().numpy()\n",
    "\n",
    "# Compute Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "conf_matrix = confusion_matrix(true_labels, pred_labels)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306313a-a8fd-4601-86ba-6c0feb54fa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Cancer vs Non-Cancer for new abstracts\n",
    "def predict(text):\n",
    "    inputs = tokenizer(text, truncation=True, padding=\"max_length\", max_length=512, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = F.softmax(logits, dim=-1).squeeze()\n",
    "        pred_label = torch.argmax(probs).item()\n",
    "    return pd.Series([\"Cancer\" if pred_label == 1 else \"Non-Cancer\", probs[0].item(), probs[1].item()])\n",
    "\n",
    "# Apply classification on dataset\n",
    "df[[\"Predicted_Category\", 'Non-Cancer Score', 'Cancer Score']] = df[\"Abstract\"].apply(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956dd24d-2628-4750-9ae6-f9d5081c50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cc5b5-8bce-4c74-9e00-e107371dfdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
